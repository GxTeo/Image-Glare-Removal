{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../GCNet\")\n",
    "from GCNet_model import GCNet\n",
    "import torch \n",
    "from torch.utils.data import random_split\n",
    "import numpy as np\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.nn import MSELoss, L1Loss\n",
    "from torch.optim import Adam\n",
    "\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, images_dir, transform=None):\n",
    "        self.images = sorted(os.listdir(images_dir))\n",
    "        self.images_dir = images_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(os.path.join(self.images_dir, self.images[idx]))\n",
    "        #image = image.convert('RGB')\n",
    "\n",
    "\n",
    "        # Split the image \n",
    "        width, height = image.size        \n",
    "        truth_image = image.crop((0, 0, width // 3, height))\n",
    "        glare_image = image.crop((width // 3, 0, (width//3)*2, height))\n",
    "\n",
    "        if self.transform:\n",
    "            truth_image = self.transform(truth_image)\n",
    "            glare_image = self.transform(glare_image)\n",
    "\n",
    "            truth_image = truth_image.expand(3, -1, -1)\n",
    "            glare_image = glare_image.expand(3, -1, -1)\n",
    "\n",
    "        return glare_image, truth_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    # change to grayscale\n",
    "    transforms.Grayscale(),\n",
    "    transforms.Resize((512, 512)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCNet(in_channels=3, out_channels=3).to(device)\n",
    "model.load_state_dict(torch.load(\"../GCNet/GCNet_weight.pth\", map_location=device),strict=False)\n",
    "# Freeze all layers\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Unfreeze the last few layers\n",
    "for param in model.final4.parameters():\n",
    "    param.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCNet(\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (up): Interpolate()\n",
       "  (conv0_0): GCVGGBlock(\n",
       "    (model): Sequential(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (conv1_0): GCVGGBlock(\n",
       "    (model): Sequential(\n",
       "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (conv2_0): GCVGGBlock(\n",
       "    (model): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (conv3_0): GCVGGBlock(\n",
       "    (model): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (conv4_0): GCVGGBlock(\n",
       "    (model): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (conv0_1): GCVGGBlock(\n",
       "    (model): Sequential(\n",
       "      (0): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (conv1_1): GCVGGBlock(\n",
       "    (model): Sequential(\n",
       "      (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (conv2_1): GCVGGBlock(\n",
       "    (model): Sequential(\n",
       "      (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (conv3_1): GCVGGBlock(\n",
       "    (model): Sequential(\n",
       "      (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (conv0_2): GCVGGBlock(\n",
       "    (model): Sequential(\n",
       "      (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (conv1_2): GCVGGBlock(\n",
       "    (model): Sequential(\n",
       "      (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (conv2_2): GCVGGBlock(\n",
       "    (model): Sequential(\n",
       "      (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (conv0_3): GCVGGBlock(\n",
       "    (model): Sequential(\n",
       "      (0): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (conv1_3): GCVGGBlock(\n",
       "    (model): Sequential(\n",
       "      (0): Conv2d(320, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (conv0_4): GCVGGBlock(\n",
       "    (model): Sequential(\n",
       "      (0): Conv2d(192, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (final1): Sequential(\n",
       "    (0): Conv2d(32, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (final2): Sequential(\n",
       "    (0): Conv2d(32, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (final3): Sequential(\n",
       "    (0): Conv2d(32, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (final4): Sequential(\n",
       "    (0): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    (3): Conv2d(32, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (G_x_D): Conv2d(3, 1, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "  (G_y_D): Conv2d(3, 1, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "  (G_x_G): Conv2d(3, 1, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "  (G_y_G): Conv2d(3, 1, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '../SD1/train'\n",
    "dataset = ImageDataset(train_path, transform=transform)\n",
    "\n",
    "\n",
    "# Assuming dataset is already defined\n",
    "total_size = len(dataset)\n",
    "train_size = int(total_size * 0.8)  # 80% for training\n",
    "val_size = total_size - train_size  # Remaining 20% for validation\n",
    "\n",
    "# Perform the split\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] Training: 100%|██████████| 4800/4800 [31:44<00:00,  2.52it/s, loss=0.0333]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], MSE Loss: 0.2936, L1 Loss: 0.33946515616960826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] Validation: 100%|██████████| 600/600 [07:12<00:00,  1.39it/s, loss=0.154] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 Validation Loss: 0.1254\n",
      "Saved Best Model with Validation Loss: 0.1254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/10] Training: 100%|██████████| 4800/4800 [32:03<00:00,  2.50it/s, loss=0.0195] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], MSE Loss: 0.0314, L1 Loss: 0.13087072954745962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/10] Validation: 100%|██████████| 600/600 [07:12<00:00,  1.39it/s, loss=0.122] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 Validation Loss: 0.1021\n",
      "Saved Best Model with Validation Loss: 0.1021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [3/10] Training: 100%|██████████| 4800/4800 [31:56<00:00,  2.50it/s, loss=0.0105] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], MSE Loss: 0.0210, L1 Loss: 0.10954819753067568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [3/10] Validation: 100%|██████████| 600/600 [07:12<00:00,  1.39it/s, loss=0.12]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 Validation Loss: 0.0964\n",
      "Saved Best Model with Validation Loss: 0.0964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [4/10] Training: 100%|██████████| 4800/4800 [31:57<00:00,  2.50it/s, loss=0.0137] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], MSE Loss: 0.0179, L1 Loss: 0.10216635415252918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [4/10] Validation: 100%|██████████| 600/600 [07:11<00:00,  1.39it/s, loss=0.114] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 Validation Loss: 0.0910\n",
      "Saved Best Model with Validation Loss: 0.0910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [5/10] Training: 100%|██████████| 4800/4800 [32:05<00:00,  2.49it/s, loss=0.00961]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], MSE Loss: 0.0168, L1 Loss: 0.09934377415648972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [5/10] Validation: 100%|██████████| 600/600 [07:20<00:00,  1.36it/s, loss=0.115] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 Validation Loss: 0.0943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [6/10] Training:  47%|████▋     | 2254/4800 [15:07<17:29,  2.43it/s, loss=0.0156] "
     ]
    }
   ],
   "source": [
    "mse_criterion = MSELoss().to(device)\n",
    "l1_criterion = L1Loss().to(device)\n",
    "optimizer = Adam(model.parameters(), lr=1e-5)\n",
    " \n",
    "# Training loop\n",
    "num_epochs = 10\n",
    " \n",
    "# Variable to keep track of the best validation loss\n",
    "best_val_loss = float('inf')\n",
    "if not os.path.exists('../checkpoint'):\n",
    "    os.makedirs(['../checkpoint'])\n",
    "best_model_path = \"../checkpoint/best_model.pth\"\n",
    "\n",
    " \n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_l1_loss = 0.0\n",
    " \n",
    "    # Training phase with progress bar\n",
    "    train_pbar = tqdm(train_dataloader, desc=f\"Epoch [{epoch+1}/{num_epochs}] Training\")\n",
    "    for glare_images, truth_images in train_pbar:\n",
    "        glare_images, truth_images = glare_images.to(device), truth_images.to(device)\n",
    " \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    " \n",
    "        # Forward pass\n",
    "        outputs = model(glare_images)\n",
    " \n",
    "        # Compute the loss\n",
    "        loss = mse_criterion(outputs, truth_images)\n",
    "        l1_loss = l1_criterion(outputs, truth_images)\n",
    "\n",
    "\n",
    " \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    " \n",
    "        running_loss += loss.item() * glare_images.size(0)\n",
    "        running_l1_loss += l1_loss.item() * glare_images.size(0)\n",
    " \n",
    "        # Update progress bar\n",
    "        train_pbar.set_postfix(loss=loss.item())\n",
    " \n",
    "    epoch_loss = running_loss / len(train_dataloader.dataset)\n",
    "    l1_epoch_loss = running_l1_loss / len(train_dataloader.dataset)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], MSE Loss: {epoch_loss:.4f}, L1 Loss: {l1_epoch_loss}')\n",
    " \n",
    "    # Validation phase with progress bar\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    " \n",
    "    val_pbar = tqdm(val_dataloader, desc=f\"Epoch [{epoch+1}/{num_epochs}] Validation\")\n",
    "    with torch.no_grad():\n",
    "        for glare_images, truth_images in val_pbar:\n",
    "            glare_images, truth_images = glare_images.to(device), truth_images.to(device)\n",
    " \n",
    "            # Forward pass\n",
    "            outputs = model(glare_images)\n",
    " \n",
    "            # Compute L1 loss\n",
    "            loss = l1_criterion(outputs, truth_images)\n",
    " \n",
    "            val_loss += loss.item() * glare_images.size(0)\n",
    " \n",
    "            # Update progress bar\n",
    "            val_pbar.set_postfix(loss=loss.item())\n",
    " \n",
    "    val_loss /= len(val_dataloader.dataset)\n",
    "    print(f'L1 Validation Loss: {val_loss:.4f}')\n",
    " \n",
    "    # Save the model if the validation loss is the best we've seen so far\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f'Saved Best Model with Validation Loss: {val_loss:.4f}')\n",
    " \n",
    "print('Training complete.')\n",
    "print(f'Best validation loss: {best_val_loss:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
